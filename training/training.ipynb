{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Download dataset\n",
    "I've found that I've had some problems with unzip/shutil on this file. I'd suggest using 7zip to download it. You'll get an error that looks like this, but it'll still work.\n",
    "```\n",
    "ERRORS:\n",
    "Headers Error\n",
    "\n",
    "--\n",
    "Path = /home/stephen/ds1/ds1.zip\n",
    "Type = zip\n",
    "ERRORS:\n",
    "Headers Error\n",
    "Physical Size = 11582983320\n",
    "64-bit = +\n",
    "Archives with Errors: 1\n",
    "```\n",
    "You will need to install 7zip command line for the unzipping to work, on ubuntu this can be done with ``apt install 7z``"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import wget\n",
    "from pathlib import Path\n",
    "path_to_data = \"data/Dataset 1 (Simplex)/\"\n",
    "if not Path(path_to_data).exists():\n",
    "    wget.download('http://staff.ee.sun.ac.za/mjbooysen/Potholes/Slow/Dataset 1 (Simplex).zip',out='dataset.zip')\n",
    "    out = Popen(\"7z x dataset.zip -odata\",shell=True,stdin=PIPE, stdout=PIPE, stderr=STDOUT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Allow matplotlib to render inside the notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Required dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.optim import adam\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the pretrained mobilenet model from [torchivision.models](https://pytorch.org/docs/stable/torchvision/models.html)\n",
    "\n",
    "As the name implies, this is a much lighter weight convolutional neural network designed to be run on devices with limited compute capacity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = mobilenet_v2(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use CUDA to offload training to the GPU if possible, otherwise use CPU (Will be significantly slower if training on a CPU)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "model.cuda(device=device)\n",
    "print(f\"Using device {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm going to be using the [ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) \n",
    "dataloader to automatically create the correct inputs and classes, in this case the two classes it creates are\n",
    " ``positive`` and ``negative`` based on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_path = Path(str(path_to_data) + \"/Train data\")\n",
    "listdir(train_path.absolute())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Augmentation is a good way to increase the training accuracy of a dataset [Table 3, Wang, Perez 2017](http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf)\n",
    "\n",
    "Torchivision gives us some easy to use transforms to augment our training images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([512,512]),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(brightness=[0.8,1.2],contrast=[0.8,1.2],saturation=[1,2],hue=[-0.2,0.2]),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the test/train datasets. Will split this in another step.\n",
    "train_data = ImageFolder(root=train_path.absolute(),transform=transform)\n",
    "test_data = ImageFolder(root=train_path.absolute(),transform=transform)\n",
    "# Split this into a test and train set\n",
    "samples_test,samples_train,targets_test,targets_train = train_test_split(train_data.samples,train_data.targets,test_size = .8,random_state=42,stratify=train_data.targets)\n",
    "test_data.targets = targets_test\n",
    "train_data.targets = targets_train\n",
    "test_data.samples = samples_test\n",
    "train_data.samples = samples_train\n",
    "# Turn these datasets into DataLoaders (generators)\n",
    "test_data_loader = DataLoader(test_data,batch_size=12,shuffle=True,num_workers=0,)\n",
    "\n",
    "train_data_loader = DataLoader(train_data,batch_size=12,shuffle=True,num_workers=0)\n",
    "print(f\"Using classes {test_data.classes}\")\n",
    "print(f\"There are {len(train_data.samples)} items in training data\")\n",
    "print(f\"There are {len(test_data.samples)} items in validation data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The current model assumes you're going to have a lot more outputs as it was predicting 1000 classes as part of ImagNet. \n",
    "We're going to chop this classifier layer off and put our own one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Existing classifier\")\n",
    "print(model.classifier )\n",
    "model.classifier = nn.Sequential(nn.Dropout(p=0.2,inplace=True),\n",
    "                                 nn.Linear(in_features=1280,out_features=len(test_data.classes)))\n",
    "print(\"New classifier\")\n",
    "print(model.classifier)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the first part of training, were going to freeze a majority of the layer weights and only train the classifier initially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "using cross entroy as a loss function since this is a binary classification problem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "torch.cuda.set_device(device)\n",
    "# Suppress model output\n",
    "_ = model.cuda(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a generic training function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_epoch(model, data_loader, train,optimizer,lr_optim):\n",
    "    losses = []\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for input,label in tqdm(data_loader):\n",
    "        in_dat = input.to(device=device, dtype=torch.float)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(in_dat)\n",
    "            loss_val = criteria(outputs,label)\n",
    "            losses.append(loss_val.item())\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            lr_optim.step()\n",
    "        else:\n",
    "            outputs = model(in_dat)\n",
    "            loss_val = criteria(outputs,label)\n",
    "            losses.append(loss_val.item())\n",
    "    return losses[0]\n",
    "\n",
    "\n",
    "def train(train_dl, test_dl,model,learning_rate,epoches):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    optimizer = adam.Adam(model.parameters(),lr=learning_rate)\n",
    "    lr_optim = lr_scheduler.CosineAnnealingLR(optimizer,len(train_dl))\n",
    "    for epoch in range(0,epoches):\n",
    "        trn_loss = run_epoch(model, train_dl,train=True,optimizer=optimizer,lr_optim=lr_optim)\n",
    "        val_loss = run_epoch(model, test_dl,train=False,optimizer=optimizer,lr_optim=lr_optim)\n",
    "        # return averages of the epoch\n",
    "        train_losses.append(np.average(trn_loss)) \n",
    "        valid_losses.append(np.average(val_loss))\n",
    "    plt.clf()\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(valid_losses)\n",
    "    plt.legend(['training losses','validation losses'])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and validation loss of model\")\n",
    "    plt.show()\n",
    "    return train_losses, valid_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_loss, v_loss = train(train_data_loader,test_data_loader,model,learning_rate=0.001,epoches=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model,'firststep.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take approx the last half of the parameters and set them to trainable\n",
    "param_count = 0\n",
    "for param in model.parameters():\n",
    "    if param_count > 130:\n",
    "        param.requires_grad = True\n",
    "t_loss, v_loss = train(train_data_loader,test_data_loader,model,learning_rate=0.0001,epoches=10)  \n",
    "torch.save(model,'secondstep.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train every parameter but with a very low learning rate\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "t_loss, v_loss = train(train_data_loader,test_data_loader,model,learning_rate=0.00001,epoches=6)\n",
    "torch.save(model,'thirdstep.model')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}